{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOUMAHORO Youssouf\n",
    "## Enseignant: Olaf KOUAMO\n",
    "\n",
    "### TP: Manipulation de DataFrame avec Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(\"metastore_db/db.lck\")\n",
    "    os.remove(\"metastore_db/dbex.lck\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def build_spark_session(app_name, memory='4g', executors=4):\n",
    "    return SparkSession.builder\\\n",
    "                      .appName(app_name)\\\n",
    "                      .config('spark.executor.memory', memory)\\\n",
    "                      .config('spark.executor.instances', executors)\\\n",
    "                      .getOrCreate()\n",
    "\n",
    "spark_session = build_spark_session(app_name='ok-google')\n",
    "\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark_session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e82fb55e8f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m      (datetime.date(2018,4,12), 'MBra',36)]\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_people\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mpeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mschemaPeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeople\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark_session' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "import datetime\n",
    "\n",
    "list_people = [(datetime.date(2018,1,3), 'Ankit',25),\n",
    "     (datetime.date(2018,2,3), 'Jalfaizy',22),\n",
    "     (datetime.date(2018,1,5), 'saurabh',20),\n",
    "     (datetime.date(2018,1,12), 'Bala',26),\n",
    "     (datetime.date(2018,7,9), 'Jules',19) ,\n",
    "     (datetime.date(2018,3,18), 'Arild',43),\n",
    "     (datetime.date(2018,1,5), 'sarah',20),\n",
    "     (datetime.date(2018,8,12), 'Boly',33),\n",
    "     (datetime.date(2018,4,6), 'Anita',35),\n",
    "     (datetime.date(2018,12,6), 'Jules',22),\n",
    "     (datetime.date(2018,7,24), 'Soul',20),\n",
    "     (datetime.date(2018,6,17), 'Gral',54),\n",
    "     (datetime.date(2018,9,7), 'Apoh',18),\n",
    "     (datetime.date(2018,10,4), 'Dony',32),\n",
    "     (datetime.date(2018,2,5), 'Tanoh',31),\n",
    "     (datetime.date(2018,11,12), 'Issouf',27),\n",
    "     (datetime.date(2018,10,3), 'Bilé',29),\n",
    "     (datetime.date(2018,5,3), 'Gagnon',20),\n",
    "     (datetime.date(2018,3,5), 'Papiss',28),\n",
    "     (datetime.date(2018,2,12), 'Kravitz',34),\n",
    "     (datetime.date(2018,5,9), 'Mouli',35),\n",
    "     (datetime.date(2018,8,3), 'Jacques',27),\n",
    "     (datetime.date(2018,12,5), 'soum',22),\n",
    "     (datetime.date(2018,4,12), 'MBra',36)]\n",
    "\n",
    "rdd = spark_session.sparkContext.parallelize(list_people)\n",
    "people = rdd.map(lambda x: Row(date=x[0], name=x[1], age=int(x[2])))\n",
    "schemaPeople = spark_session.createDataFrame(people)\n",
    "schemaPeople.toPandas()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1- compter le nombre de personne totale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaPeople.count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2- compter le nombre de fille et de garcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| sexe|count|\n",
      "+-----+-----+\n",
      "|fille|   14|\n",
      "|homme|   10|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.groupby('sexe').count().show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3- quel est l'age moyen, median mini et maxi dans chaque groupe (garcon, fille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = schemaPeople.groupBy('sexe').agg(f.count(\"sexe\").alias(\"nb_Pers\"),\n",
    "                                 f.mean(\"age\").alias(\"moyenne\"),\n",
    "                                f.min(\"age\").alias(\"minAge\"),\n",
    "                                f.max(\"age\").alias(\"maxAge\")).toPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de fille\n",
    "med_G = schemaPeople.filter(schemaPeople.sexe==\"fille\").approxQuantile(\"age\", [0.5],0.000001)\n",
    "med_F = schemaPeople.filter(schemaPeople.sexe==\"homme\").approxQuantile(\"age\", [0.5],0.000001)\n",
    "median = med_G+med_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|median|\n",
      "+------+\n",
      "|  25.0|\n",
      "|  28.0|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark_session.sparkContext.parallelize(median)\n",
    "p = rdd.map(lambda x: Row(median=x))\n",
    "med = spark_session.createDataFrame(p)\n",
    "med.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4 - quelle est la date de dernière visite de chaque client par rapport à la date d'aujourd'hui (la colonne date correspond à la date de visite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = schemaPeople.select(\"*\",\n",
    "                         f.lit(datetime.date.today()).alias(\"date_max\"))\n",
    "df = dd.select(\"*\", f.datediff('date_max', 'date')\\\n",
    "                    .alias('days_since_last_visit'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5 - quels sont les personnes qui ont une date de visite < 400 jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['days_since_last_visit'] < 400).count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " 6- Vérifions si existe ds valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+---------------------+\n",
      "|age|name|sexe|days_since_last_visit|\n",
      "+---+----+----+---------------------+\n",
      "|  0|   0|   0|                    0|\n",
      "+---+----+----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,sum\n",
    "df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).toPandas()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7- rajouter une colonne mois correspondant au mois de chaque de chaque individu dans la data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-----+----+\n",
      "|age|      date|    name| sexe|mois|\n",
      "+---+----------+--------+-----+----+\n",
      "| 25|2018-01-03|   Ankit|fille|   1|\n",
      "| 22|2018-02-03|Jalfaizy|fille|   2|\n",
      "| 20|2018-01-05| saurabh|fille|   1|\n",
      "| 26|2018-01-12|    Bala|fille|   1|\n",
      "| 19|2018-07-09|   sarah|fille|   7|\n",
      "+---+----------+--------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "F1 = udf(lambda x: x.month)\n",
    "schemaPeople.withColumn(\"mois\",F1(schemaPeople[\"date\"])).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autre methode\n",
    "schemaPeople.withColumn(\"mois\",f.month(schemaPeople[\"date\"])).show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. créer une colonne adulte qui prendra la valeur 0 pour les personnes de moins de 25ans et 1 sinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-----+------+\n",
      "|age|      date|    name| sexe|adulte|\n",
      "+---+----------+--------+-----+------+\n",
      "| 25|2018-01-03|   Ankit|fille|     1|\n",
      "| 22|2018-02-03|Jalfaizy|fille|     0|\n",
      "| 20|2018-01-05| saurabh|fille|     0|\n",
      "| 26|2018-01-12|    Bala|fille|     1|\n",
      "| 19|2018-07-09|   sarah|fille|     0|\n",
      "+---+----------+--------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaPeople.withColumn(\"adulte\",f.when(schemaPeople[\"age\"] < 25,0).when(schemaPeople[\"age\"] >= 25,1)).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
