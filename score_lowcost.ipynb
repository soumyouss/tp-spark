{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOUMAHORO Youssouf\n",
    "### Enseignant: Olaf KOUAMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP: scoring-lowcost\n",
    "\n",
    "    objectif: redire l'appentence des clients a des transport lowcoast.\n",
    "              Pour cela, nous utiliserons la librairie Ml de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.remove(\"metastore_db/db.lck\")\n",
    "    os.remove(\"metastore_db/dbex.lck\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def build_spark_session(app_name, memory='4g', executors=4):\n",
    "    return SparkSession.builder\\\n",
    "                      .appName(app_name)\\\n",
    "                      .config('spark.executor.memory', memory)\\\n",
    "                      .config('spark.executor.instances', executors)\\\n",
    "                      .getOrCreate()\n",
    "\n",
    "spark_session = build_spark_session(app_name='ok-google')\n",
    "\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desciption des fichiers de données"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perimetre: représente les identifaints des clients accessible à l'étude.\n",
    "histo_client: represente l'historique des données clients sur une période donnée\n",
    "histo_train: represente l'historique des données de commandes trains.\n",
    "histo_lowcost: represente l'historique des données de client lowcost (défini avec le métier).\n",
    "visites: représente l'historique des données de navigation des clients sur le site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travail à faire"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 - lire les fichiers de données\n",
    "2 - identifier les variables continues et transformer leurs modalités en double.\n",
    "3 - joindre les differentes sources de données en se basant sur les données du périmètre (tous les individus du périmèetre devront apparaitre dans la jointure avec des valeurs NULL si nécessaire pour les colonnes en provenance d'autres sources).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - joindre les dataframe sur la clé ID_CLIENT en concervant tous les clients du périmètre.\n",
    "2 - compter le nombre de ID_CLIENT et vérifier qu'il correspond aux nombre d'ID_CLIENT dans la variable perimètre.\n",
    "3 - Caster les variables continues en double et sauvergarder alors le df obtenu dans le repertoire data sur le cluster.\n",
    "4 - Pour les variables catégorielles, créer une nouvelle variable qui prend la modalité de la variable courante si elle existe et \"NA\" sinon.\n",
    "5- Verifier la cohérence des variables continue. Par exemple pour une variable comme age mettre à -1 tous les ages <0 ou>120ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lecture des fichiers\n",
    "perimetre = spark_session.read.csv(\"data_clients/sample_perimetre.csv\", header=True)\n",
    "histo_client_raw = spark_session.read.csv(\"data_clients/sample_histo_client.csv\", header=True)\n",
    "histo_train_raw = spark_session.read.csv(\"data_clients/sample_histo_train.csv\", header=True)\n",
    "histo_lowcost_raw = spark_session.read.csv(\"data_clients/sample_histo_lowcost.csv\", header=True)\n",
    "visites_raw = spark_session.read.csv(\"data_clients/sample_visites.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('nb_od', 'string'),\n",
       " ('mean_nb_passagers', 'string'),\n",
       " ('mean_duree_voyage', 'string'),\n",
       " ('mean_mt_voyage', 'string'),\n",
       " ('mean_tarif_loisir', 'string'),\n",
       " ('mean_classe_1', 'string'),\n",
       " ('mean_pointe', 'string'),\n",
       " ('mean_depart_we', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo_train_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('anciennete', 'string'),\n",
       " ('recence_cmd', 'string'),\n",
       " ('AGE', 'string'),\n",
       " ('LBL_STATUT_CLT', 'string'),\n",
       " ('LBL_GEO_AIR', 'string'),\n",
       " ('LBL_GRP_SEGMENT_NL', 'string'),\n",
       " ('LBL_SEG_COMPORTEMENTAL', 'string'),\n",
       " ('LBL_GEO_TRAIN', 'string'),\n",
       " ('LBL_SEGMENT_ANTICIPATION', 'string'),\n",
       " ('FLG_CMD_CARTE_1225', 'string')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo_client_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Fonction pour transformer pour caster \n",
    "def cast_columns_of_df(df, cols_to_cast, col_to_keep, cast_type='double'):\n",
    "    \"\"\"cast continuous columns into double since all columns are \"\"\"\n",
    "    return df.select(col_to_keep + [(df[feature].cast(cast_type))\n",
    "                    for feature in cols_to_cast if 'ID_CLIENT' not in feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons transformer certaines variables de notre ensemble de données en **double** ou **int**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast_to_float\n",
    "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
    "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
    "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225','anciennete','AGE']\n",
    "\n",
    "histo_train = cast_columns_of_df(histo_train_raw, histo_train_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "histo_lowcost = cast_columns_of_df(histo_lowcost_raw, histo_lowcost_raw.columns,\n",
    "                                 [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "visites = cast_columns_of_df(visites_raw, visites_raw.columns,\n",
    "                             [\"ID_CLIENT\"], cast_type='double')\n",
    "\n",
    "histo_client = cast_columns_of_df(histo_client_raw,\n",
    "                                  [\"recence_cmd\"],\n",
    "                                  client_cols_to_keep,\n",
    "                                 cast_type='double')\n",
    "#cast_to_int\n",
    "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
    "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
    "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225','recence_cmd']\n",
    "\n",
    "histo_client = cast_columns_of_df(histo_client,\n",
    "                                  [\"anciennete\",'AGE'],\n",
    "                                  client_cols_to_keep,\n",
    "                                 cast_type='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('LBL_STATUT_CLT', 'string'),\n",
       " ('LBL_GEO_AIR', 'string'),\n",
       " ('LBL_SEG_COMPORTEMENTAL', 'string'),\n",
       " ('LBL_GEO_TRAIN', 'string'),\n",
       " ('LBL_GRP_SEGMENT_NL', 'string'),\n",
       " ('LBL_SEGMENT_ANTICIPATION', 'string'),\n",
       " ('FLG_CMD_CARTE_1225', 'string'),\n",
       " ('recence_cmd', 'double'),\n",
       " ('anciennete', 'int'),\n",
       " ('AGE', 'int')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo_client.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('days_since_last_visit', 'double'),\n",
       " ('tx_conversion', 'double')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visites.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID_CLIENT', 'string'),\n",
       " ('nb_od', 'double'),\n",
       " ('mean_nb_passagers', 'double'),\n",
       " ('mean_duree_voyage', 'double'),\n",
       " ('mean_mt_voyage', 'double'),\n",
       " ('mean_tarif_loisir', 'double'),\n",
       " ('mean_classe_1', 'double'),\n",
       " ('mean_pointe', 'double'),\n",
       " ('mean_depart_we', 'double')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histo_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### faire une jointure entre les informations des différentes tables.\n",
    "     NB: on conservera tous les clients de la table perimetre.\n",
    "        En effet, ce sont les cleints qu'on souhaite scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = perimetre.join(histo_client,on='ID_CLIENT',how='left_outer')\\\n",
    "       .join(visites,on='ID_CLIENT',how='left_outer')\\\n",
    "       .join(histo_train,on='ID_CLIENT',how='left_outer')\\\n",
    "        .join(histo_lowcost,on='ID_CLIENT',how='left_outer')\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification\n",
    "perimetre.count()==df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combien a t'on de features quatitatives, qualitatives \n",
    "     Pour nous faciliter la tache, nousa allons créer une fonction qui va nous renvoyer la liste des\n",
    "     features continues et celle des features qualitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction prend en paramètre df.dtypes et renvoi les listes de features continues et qualitative\n",
    "\n",
    "def type_feature(df_dtype):\n",
    "    continous_columns=list()\n",
    "    qualifies_columns=list()\n",
    "    \n",
    "    for col in range(len(df_dtype)):\n",
    "        \n",
    "        if(df_dtype[col][1]=='string'):\n",
    "            qualifies_columns.append(df_dtype[col][0])\n",
    "            \n",
    "        else:\n",
    "            continous_columns.append(df_dtype[col][0])\n",
    "    \n",
    "    return(continous_columns,qualifies_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recence_cmd',\n",
       " 'anciennete',\n",
       " 'AGE',\n",
       " 'days_since_last_visit',\n",
       " 'tx_conversion',\n",
       " 'nb_od',\n",
       " 'mean_nb_passagers',\n",
       " 'mean_duree_voyage',\n",
       " 'mean_mt_voyage',\n",
       " 'mean_tarif_loisir',\n",
       " 'mean_classe_1',\n",
       " 'mean_pointe',\n",
       " 'mean_depart_we',\n",
       " 'flg_cmd_lowcost',\n",
       " 'flg_track_nl_lowcost',\n",
       " 'flg_track_nl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=type_feature(df.dtypes)\n",
    "features[0] # les features continues\n",
    "#features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features continues: 16\n",
      "features qualitatives: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"features continues: {}\".format(len(type_feature(df.dtypes)[0])))\n",
    "print(\"features qualitatives: {}\".format(len(type_feature(df.dtypes)[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les features avec valeurs manquantes\n",
    "     # Cette fonction renvoie un data frame contenant les features le nombre de valeurs manquantes\n",
    "     qu'elles contiennent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_CLIENT</th>\n",
       "      <th>LBL_STATUT_CLT</th>\n",
       "      <th>LBL_GEO_AIR</th>\n",
       "      <th>LBL_SEG_COMPORTEMENTAL</th>\n",
       "      <th>LBL_GEO_TRAIN</th>\n",
       "      <th>LBL_GRP_SEGMENT_NL</th>\n",
       "      <th>LBL_SEGMENT_ANTICIPATION</th>\n",
       "      <th>FLG_CMD_CARTE_1225</th>\n",
       "      <th>recence_cmd</th>\n",
       "      <th>anciennete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78998</td>\n",
       "      <td>162977</td>\n",
       "      <td>155160</td>\n",
       "      <td>163010</td>\n",
       "      <td>79522</td>\n",
       "      <td>157822</td>\n",
       "      <td>10283</td>\n",
       "      <td>1484</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_CLIENT  LBL_STATUT_CLT  LBL_GEO_AIR  LBL_SEG_COMPORTEMENTAL  \\\n",
       "0          0           78998       162977                  155160   \n",
       "\n",
       "   LBL_GEO_TRAIN  LBL_GRP_SEGMENT_NL  LBL_SEGMENT_ANTICIPATION  \\\n",
       "0         163010               79522                    157822   \n",
       "\n",
       "   FLG_CMD_CARTE_1225  recence_cmd  anciennete  \n",
       "0               10283         1484          55  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_feature_missing_values(df):\n",
    "    from pyspark.sql.functions import col,sum\n",
    "    return df.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns)).toPandas().iloc[:,0:10]\n",
    "\n",
    "find_feature_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplacement des valeurs manquantes\n",
    "    Nous allons remplacer les valeurs manquantes dans les features par le -1 si la feature est \n",
    "    qualitative ou par la moyenne si elle est continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flg_cmd_lowcost'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appel à la fonction\n",
    "features=type_feature(df.dtypes)\n",
    "features[1].append('flg_cmd_lowcost')\n",
    "features[0].pop(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dico des moyennes des features continues\n",
    "dic_mean={}\n",
    "for feat in features[0]:\n",
    "    dic_mean[feat]= df.groupBy().avg(feat).take(1)[0][0]\n",
    "\n",
    "\n",
    "df1=df.select([f.when(df[feature].isNotNull(),df[feature]).otherwise(\"-1\").alias(feature) \\\n",
    "               for feature in features[1]]+[f.when(df[feature].isNotNull(),\\\n",
    "                                df[feature]).otherwise(dic_mean[feature]).alias(feature)\\\n",
    "                               for feature in features[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autres fonctions pour remplacer les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction to replace missing values\n",
    "def replace_missing_values1(df,qualifies_columns, continuous_columns):\n",
    "    dict_mean = {feat: df.select(f.mean(feat)).collect()[0][0] \n",
    "                 for feat in continuous_columns}\n",
    "    return df.select([f.when(df[feature].isNotNull(), df[feature])\\\n",
    "                      .otherwise('-1').alias(feature) for feature in qualifies_columns]\\\n",
    "                     +[f.when(df[feature].isNotNull(), df[feature])\\\n",
    "                       .otherwise(dict_mean[feature]).alias(feature) \n",
    "                       for feature in continuous_columns])\n",
    "\n",
    "# Another fonction\n",
    "def replace_missing_values2(df,qualifies_columns, continuous_columns):\n",
    "    \n",
    "    return df.select([f.when(df[feature].isNotNull(), df[feature])\\\n",
    "                      .otherwise('-1').alias(feature) for feature in qualifies_columns]\\\n",
    "                     +[f.when(df[feature].isNotNull(), df[feature])\\\n",
    "                       .otherwise(df.select(f.mean(df[feature])).collect()[0][0])\\\n",
    "                       .alias(feature) for feature in continuous_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID_CLIENT: string (nullable = true)\n",
      " |-- LBL_STATUT_CLT: string (nullable = true)\n",
      " |-- LBL_GEO_AIR: string (nullable = true)\n",
      " |-- LBL_SEG_COMPORTEMENTAL: string (nullable = true)\n",
      " |-- LBL_GEO_TRAIN: string (nullable = true)\n",
      " |-- LBL_GRP_SEGMENT_NL: string (nullable = true)\n",
      " |-- LBL_SEGMENT_ANTICIPATION: string (nullable = true)\n",
      " |-- FLG_CMD_CARTE_1225: string (nullable = true)\n",
      " |-- flg_cmd_lowcost: string (nullable = true)\n",
      " |-- recence_cmd: double (nullable = true)\n",
      " |-- anciennete: double (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- days_since_last_visit: double (nullable = true)\n",
      " |-- tx_conversion: double (nullable = true)\n",
      " |-- nb_od: double (nullable = true)\n",
      " |-- mean_nb_passagers: double (nullable = true)\n",
      " |-- mean_duree_voyage: double (nullable = true)\n",
      " |-- mean_mt_voyage: double (nullable = true)\n",
      " |-- mean_tarif_loisir: double (nullable = true)\n",
      " |-- mean_classe_1: double (nullable = true)\n",
      " |-- mean_pointe: double (nullable = true)\n",
      " |-- mean_depart_we: double (nullable = true)\n",
      " |-- flg_track_nl_lowcost: double (nullable = true)\n",
      " |-- flg_track_nl: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Les differentes modalites de la feature **LBL_STATUT_CLT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      LBL_STATUT_CLT|\n",
      "+--------------------+\n",
      "|         Moyen moins|\n",
      "|Non present dans ...|\n",
      "|    Nouveau prospect|\n",
      "|            Prospect|\n",
      "|          Tres petit|\n",
      "|                null|\n",
      "|               Petit|\n",
      "|             Inactif|\n",
      "|       Nouveau actif|\n",
      "|               Grand|\n",
      "|          Tres grand|\n",
      "|          Moyen plus|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df[\"LBL_STATUT_CLT\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstitution des données\n",
    "     Nous allons maintenant reconstituer notre jeu de données en créant des features pour répondre à \n",
    "     notre problématique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_df(df):\n",
    "    ds = df.select('ID_CLIENT',\n",
    "    f.when(df.LBL_GEO_TRAIN.isin(['Toulouse', 'Lille', 'Dijon',\n",
    "                                  'Lyon', 'Marseille', 'Paris',\n",
    "                                  'Nice', 'Limoges','Rouen','Rennes',\n",
    "                                  'Montpellier', 'Bordeaux', 'Metz',\n",
    "                                  'Strasbourg']), df.LBL_GEO_TRAIN)\\\n",
    "               .otherwise('na').alias('geo_train'),\n",
    "    f.when(df.LBL_GEO_AIR.isin(['Aéroports de Paris Orly',\n",
    "                                'Aéroport de Bâle-Mulhouse / Bassel',\n",
    "                                'Aéroport Lille Lesquin', 'Aéroport de Rennes',\n",
    "                                'Aéroport de Nantes Atlantique',\n",
    "                                'Aéroport de Marseille Provence  (MRS)', \n",
    "                                'Aéroport de Bordeaux Mérignac',\n",
    "                                'Aéroports de Paris Roissy-Charles-de Gaulle', \n",
    "                                \"Aéroport de Nice Côte d'Azur\",\n",
    "                                'Aéroport de Strasbourg',\n",
    "                                'Aéroport de Lyon - Saint Exupéry', \n",
    "                                'Aéroport de Toulouse Blagnac']), df.LBL_GEO_AIR)\\\n",
    "               .otherwise('na').alias('geo_air'),\n",
    "    f.when(df.FLG_CMD_CARTE_1225 == '1', '1')\\\n",
    "                   .otherwise('0').alias('cc_jeunes'),\n",
    "    f.when(df.LBL_STATUT_CLT.isin(['Tres grand', 'Nouveau actif',\n",
    "                                   'Moyen moins', ' Prospect', ' Petit',\n",
    "                                   'Inactif', 'Tres petit',\n",
    "                                   'Nouveau prospect', 'Moyen plus',\n",
    "                                   'Grand']), df.LBL_STATUT_CLT)\\\n",
    "                   .otherwise('na').alias('segt_rfm'),\n",
    "    f.when(df.LBL_SEGMENT_ANTICIPATION.isin(['Peu Anticipateur', 'Tres Anticipateur',\n",
    "                                             'Anticipateur', 'Mixte', 'Non Anticipateur',\n",
    "                                             'Non Defini']), df.LBL_SEGMENT_ANTICIPATION)\\\n",
    "                   .otherwise('na').alias('segt_anticipation'),\n",
    "    f.when(df.LBL_SEG_COMPORTEMENTAL.isin(['Mono-commande',\n",
    "                                           'Comportement Pro',\n",
    "                                           'Exclusifs Agence', \n",
    "                                           'Anticipateurs Methodiques',\n",
    "                                           'Chasseurs Bons Plans', \n",
    "                                           'Rythmes scolaires', 'Nouveaux',\n",
    "                                           'Sans contraintes']),\n",
    "           df.LBL_SEG_COMPORTEMENTAL).otherwise('na').alias('segt_comportemental'), \n",
    "    f.when(df.LBL_GRP_SEGMENT_NL.isin(['Endormi', 'Spectateur', 'Acteur',\n",
    "                                       'Eteint', 'Non defini']),\n",
    "           df.LBL_GRP_SEGMENT_NL).otherwise('na').alias('segt_nl'),\n",
    "    f.when(((df.AGE > 0) & (df.AGE < 100)), df.AGE)\\\n",
    "                   .otherwise(-1).alias('age'),\n",
    "    f.when(df.recence_cmd >= 0, df.recence_cmd)\\\n",
    "                   .otherwise(-1).alias('recence_cmd'),\n",
    "    f.when(((df.mean_duree_voyage > 0) & (df.mean_duree_voyage < 750)),\n",
    "           df.mean_duree_voyage).otherwise(-1).alias('mean_duree_voyage'),\n",
    "    f.when(df.days_since_last_visit >= 0, df.days_since_last_visit)\\\n",
    "                   .otherwise(-1).alias('recence_visite'),\n",
    "    f.when(df.mean_mt_voyage > 0, df.mean_mt_voyage)\\\n",
    "                   .otherwise(-1).alias('mean_mt_voyage'),\n",
    "    f.when(df.anciennete >= 0, df.anciennete)\\\n",
    "                   .otherwise(-1).alias('anciennete'),\n",
    "    f.when(df.nb_od > 0, df.nb_od)\\\n",
    "                   .otherwise(-1).alias('nb_od'),\n",
    "    f.when(df.mean_nb_passagers > 0, df.mean_nb_passagers)\\\n",
    "                   .otherwise(-1).alias('mean_nb_passagers'),\n",
    "    f.when(df.mean_tarif_loisir >= 0, df.mean_tarif_loisir)\\\n",
    "                   .otherwise(-1).alias('mean_tarif_loisir'),\n",
    "    f.when(df.mean_classe_1 >= 0, df.mean_classe_1)\\\n",
    "                   .otherwise(-1).alias('mean_classe_1'),\n",
    "    f.when(df.mean_pointe >= 0, df.mean_pointe)\\\n",
    "                   .otherwise(-1).alias('mean_pointe'),\n",
    "    f.when(df.mean_depart_we >= 0, df.mean_depart_we)\\\n",
    "                   .otherwise(-1).alias('mean_depart_we'),\n",
    "    f.when(df.tx_conversion >= 0, df.tx_conversion)\\\n",
    "                   .otherwise(-1).alias('tx_conversion'),\n",
    "    f.when(df.flg_cmd_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_cmd_lowcost'),\n",
    "    f.when(df.flg_track_nl_lowcost == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl_lowcost'), \n",
    "    f.when(df.flg_track_nl == 1, '1')\\\n",
    "                   .otherwise('0').alias('flg_track_nl'))\n",
    "    \n",
    "    return ds\n",
    "df = input_df(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelles sont les differentes valeurs de notre label : flg_cmd_lowcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|flg_cmd_lowcost|\n",
      "+---------------+\n",
      "|              0|\n",
      "|              1|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"flg_cmd_lowcost\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### features engineering et modélisation\n",
    "\n",
    "Pour contruire un modèle en Spark il transforme le dataframe en un bon format pour que spark comprenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# StringIndexer permet d'encoder les variables quali: la modalité la présente est encodée par 0 ensuite la 2eme\n",
    "#plus présente par 1 ainsi de suite\n",
    "def preprocessed_df(df, label=\"flg_cmd_lowcostIndex\"):\n",
    "    max_values_to_define_str_cols = 10\n",
    "    id_col = 'ID_CLIENT'\n",
    "    \n",
    "    dty = dict(df.dtypes)\n",
    "    str_cols = [k for k, v in dty.items() if v == 'string']\n",
    "    str_cols.remove(id_col)\n",
    "    \n",
    "    for c in str_cols:\n",
    "        stringIndexer = StringIndexer(inputCol=c, outputCol=c+\"Index\")\n",
    "        model_str = stringIndexer.fit(df)\n",
    "        df = model_str.transform(df).drop(c)\n",
    "\n",
    "    input_cols = df.columns\n",
    "    input_cols.remove(id_col)\n",
    "    input_cols.remove(label)\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=input_cols,\n",
    "                            outputCol=\"features\")\n",
    "    df = assembler.transform(df)\n",
    "    \n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                   outputCol=\"indexedFeatures\", \n",
    "                   maxCategories=max_values_to_define_str_cols).fit(df)\n",
    "    return featureIndexer.transform(df), df\n",
    "\n",
    "\n",
    "data, dff = preprocessed_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prélevons un sample de data pour notre modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  10954\n",
      "test size:  5458\n"
     ]
    }
   ],
   "source": [
    "train = data.sample(False,0.01,seed = 0)\n",
    "test = data.sample(False,0.005,seed = 0)\n",
    "print(\"train size: \",train.count())\n",
    "print(\"test size: \",test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quelle est le label est renseigne pour la modelisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labelCol = la variable cible\n",
    "#featureCol = les variables prédictives\n",
    "lr = LogisticRegression(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                        featuresCol=\"indexedFeatures\",elasticNetParam=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustement de modele de regression logistique et calcul les coefficients de notre modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = lr.fit(train)\n",
    "# predire alors les clients lowcoast sur un sample de data n'ayant pas servi à l'apprentissage\n",
    "predictions = model_lr.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|flg_cmd_lowcostIndex|prediction|\n",
      "+--------------------+----------+\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 1.0|       1.0|\n",
      "|                 1.0|       1.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 1.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "|                 1.0|       0.0|\n",
      "|                 0.0|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(['flg_cmd_lowcostIndex','prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du modèle\n",
    "    Evaluer soit meme le score en calculant le nombre de VP, FP, VN et FN\n",
    "    on calculera alors le score qui VP+VN/VP+VN+FP+FN\n",
    "    nb: la prediction est automatiquement creee dans le data set et correspond à la colonne prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='flg_cmd_lowcostIndex', metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUC: 89.227%\n",
      "Model accuracy: 85.562%\n",
      "Model recall: 99.980%\n",
      "Model precision: 96.146%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd\n",
    "\n",
    "results = predictions.select(['prediction', 'flg_cmd_lowcostIndex'])\n",
    "labels_and_predictions = results.rdd\n",
    "metrics = MulticlassMetrics(labels_and_predictions)\n",
    "\n",
    "# AUC \n",
    "AUC = evaluator.evaluate(predictions)\n",
    "print(\"Model AUC: %.3f%%\" % (AUC * 100))\n",
    "# matrice de confusion\n",
    "cm = metrics.confusionMatrix().toArray()\n",
    "# Accuracy\n",
    "acc = (cm[0][0]+cm[1][1])/(cm.sum())\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100))\n",
    "#recall\n",
    "rec = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "print(\"Model recall: %.3f%%\" % (rec* 100))\n",
    "#precision\n",
    "prec = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "print(\"Model precision: %.3f%%\" % (prec * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ecrivons maintenant une fonction pour faire nos les moèles\n",
    "     Cette fonction prend en entrée le classifier que l'on veut ajuster, le jeu de données et le \n",
    "     label et renvoie un data frame contenant les métriques d'évaluation \n",
    "     (AUC, precision, recall, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model(df,clf,label):\n",
    "    \n",
    "    \"\"\"compute score in a classification modelisation.\n",
    "       clf: classifier\n",
    "       df: data set\n",
    "       label: target\n",
    "    \"\"\"\n",
    "    \n",
    "    train = df.sample(False,0.01,42)\n",
    "    test = df.sample(False,0.005,42)\n",
    "\n",
    "    model = clf.fit(train)\n",
    "    predictions = model.transform(test)\n",
    "    \n",
    "    results = predictions.select(['prediction', label])\n",
    "    labels_and_predictions = results.rdd\n",
    "    metrics = MulticlassMetrics(labels_and_predictions)\n",
    "    \n",
    "    AUC = evaluator.evaluate(predictions)\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "    acc = round((cm[0][0]+cm[1][1])/(cm.sum()),2)\n",
    "    rec = round(cm[0][0]/(cm[0][0]+cm[0][1]),2)\n",
    "    prec = round(cm[0][0]/(cm[0][0]+cm[1][0]),2)\n",
    "    \n",
    "    #res = {\"AUC\":AUC, \"accuracy\":acc, \"precision\": prec, \"recall\":rec}\n",
    "    res = pd.DataFrame([AUC, acc,  rec, prec],index=[\"AUC\",\"accuracy\",\"precision\",\"recall\"],\n",
    "                       columns=[\"values\"])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de la fonction compute_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.919728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             values\n",
       "AUC        0.919728\n",
       "accuracy   0.830000\n",
       "precision  1.000000\n",
       "recall     0.960000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                        featuresCol=\"indexedFeatures\",elasticNetParam=0.5)\n",
    "\n",
    "compute_model(data,clf_lr,'flg_cmd_lowcostIndex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           values\n",
       "AUC          1.00\n",
       "accuracy     0.81\n",
       "precision    1.00\n",
       "recall       0.99"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(labelCol=\"flg_cmd_lowcostIndex\", \n",
    "                                    featuresCol=\"indexedFeatures\",\n",
    "                                    maxDepth=15, numTrees=100)\n",
    "compute_model(data,classifier,'flg_cmd_lowcostIndex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "    A l'issue de ce TP nous avons appris à manipuler des données avec l'outil SPARK et à construire des\n",
    "    modèles de prédictions avec le package ml de SPARK. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
